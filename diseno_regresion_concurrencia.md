# Dise√±o   concurrencia

A continuaci√≥n se presenta una versi√≥n ampliada y m√°s completa del dise√±o para la regresi√≥n lineal empleando el paradigma de concurrencia (modelo Maestro‚ÄìTrabajador). Incluye la explicaci√≥n paso a paso y los diagramas provistos.

---

## **1. Arquitectura general del sistema concurrente**
<img width="980" height="2048" alt="image" src="https://github.com/user-attachments/assets/18e0c447-11b7-421c-9ea5-d88427f280ca" />


La regresi√≥n lineal con gradiente descendente es una operaci√≥n que puede paralelizarse dividiendo el dataset en fragmentos y enviando cada fragmento a un **Worker** que calcula los gradientes locales. Un **Coordinador** central recibe esos gradientes, los combina y actualiza los par√°metros.

### **Componentes principales:**

### **üîπ DataLoader**  
Carga el dataset y lo divide en **K particiones**. Cada partici√≥n representa un minibatch que ser√° procesado por un Worker.

### **üîπ Coordinator (Maestro)**
Controla todo el ciclo de entrenamiento:
- Inicializa Workers.
- Env√≠a par√°metros actuales (w, b).
- Recibe gradientes de cada Worker.
- Agrega los gradientes.
- Actualiza los par√°metros globales.
- Decide cu√°ndo detener el entrenamiento.

### **üîπ Workers (Trabajadores)**
Cada uno:
- Recibe par√°metros (w, b).
- Recibe un chunk de datos.
- Calcula predicciones, errores y gradientes locales.
- Env√≠a los gradientes al Aggregator.

### **üîπ Aggregator**
Realiza:
- La suma o promedio de gradientes.
- El c√°lculo final de los nuevos par√°metros.

---

## **2. Flujo detallado del algoritmo concurrente**
<img width="2048" height="843" alt="image" src="https://github.com/user-attachments/assets/df737c70-41e1-4eab-8457-5e47363e4f86" />


### **Fase 1 ‚Äî Inicializaci√≥n**
1. DataLoader divide el dataset en K trozos.  
2. Coordinator crea los Workers.  
3. Coordinator prepara los par√°metros iniciales w y b.

### **Fase 2 ‚Äî Inicio de cada √©poca**
4. Coordinator env√≠a los par√°metros **(w, b)** a cada Worker.
5. Coordinator env√≠a el chunk correspondiente a cada Worker.

### **Fase 3 ‚Äî C√°lculo paralelo**
Cada Worker ejecuta en paralelo:
- `y_pred = w * X_local + b`
- `error  = y_pred - y_local`
- `dw_local = 2/m_local * sum(error * X_local)`
- `db_local = 2/m_local * sum(error)`

### **Fase 4 ‚Äî Env√≠o de gradientes**
Cada Worker devuelve:
- `dw_local`
- `db_local`

### **Fase 5 ‚Äî Agregaci√≥n**
El Aggregator ejecuta:
- `dw = sum(dw_local)` o su promedio.
- `db = sum(db_local)` o su promedio.
- `w = w - lr * dw`
- `b = b - lr * db`

### **Fase 6 ‚Äî Repetici√≥n o terminaci√≥n**
Si no se alcanzan las √©pocas:
- Coordinator env√≠a los nuevos par√°metros a cada Worker.

Si se termin√≥:
- Coordinator env√≠a STOP a todos los Workers.








